{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b154c8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "#====================读取点云数据===================\n",
    "source = o3d.io.read_point_cloud(\"./mapping/sample_0.ply\")\n",
    "target = o3d.io.read_point_cloud(\"./mapping/sample_1.ply\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a17053d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================可视化点云初始位置===============\n",
    "o3d.visualization.draw_geometries([source, target],width=600,height=600)\n",
    "threshold = 0.2 #距离阈值\n",
    "trans_init = np.asarray([[1.0, 0.0, 0.0, 0.0],\n",
    "                         [0.0, 1.0, 0.0, 0.0],\n",
    "                         [0.0, 0.0, 1.0, 0],\n",
    "                         [0.0, 0.0, 0.0, 1.0]]) #初始变换矩阵，一般由粗配准提供"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75b4dfbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial alignment\n",
      "RegistrationResult with fitness=2.478389e-01, inlier_rmse=1.172079e-01, and correspondence_set size of 74427\n",
      "Access transformation to get result.\n",
      "Apply point-to-point ICP\n",
      "RegistrationResult with fitness=4.073872e-01, inlier_rmse=1.040227e-01, and correspondence_set size of 122340\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.95103678 -0.16441565 -0.26171842 -0.89163941]\n",
      " [ 0.24706233  0.91319294  0.32409698  0.24499192]\n",
      " [ 0.18571279 -0.37288891  0.90910099 -0.1835678 ]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "#=================================================\n",
    "#计算两个重要指标，fitness计算重叠区域（内点对应关系/目标点数）。越高越好。\n",
    "#inlier_rmse计算所有内在对应关系的均方根误差RMSE。越低越好。\n",
    "print(\"Initial alignment\")\n",
    "evaluation = o3d.pipelines.registration.evaluate_registration(source, target, threshold, trans_init)\n",
    "print(evaluation)#这里输出的是初始位置的 fitness和RMSE\n",
    "print(\"Apply point-to-point ICP\")\n",
    "icp_p2p = o3d.pipelines.registration.registration_icp(\n",
    "        source, target, threshold, trans_init,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint(),#执行点对点的ICP算法\n",
    "        o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=50))#设置最大迭代次数\n",
    "print(icp_p2p)#输出ICP相关信息\n",
    "print(\"Transformation is:\")\n",
    "print(icp_p2p.transformation)#输出变换矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8089fdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#================可视化配准结果====================\n",
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)       #由于函数transformand paint_uniform_color会更改点云，\n",
    "    target_temp = copy.deepcopy(target)       #因此调用copy.deepcoy进行复制并保护原始点云。\n",
    "#     source_temp.paint_uniform_color([1, 0, 0])#点云着色\n",
    "#     target_temp.paint_uniform_color([0, 1, 0])\n",
    "    source_temp.transform(transformation)\n",
    "#     o3d.io.write_point_cloud(\"out.ply\", source_temp)#保存点云\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp],width=600,height=600)\n",
    "draw_registration_result(source, target, icp_p2p.transformation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68252619",
   "metadata": {},
   "source": [
    "## METHOD 2 ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af8cab06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D WARNING] [ViewControl] SetViewPoint() failed because window height and width are not set.\n"
     ]
    }
   ],
   "source": [
    "o3d.visualization.draw_geometries([source])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa853811",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 1.0  #移动范围的阀值\n",
    "trans_init = np.asarray([[1,0,0,0],   # 4x4 identity matrix，这是一个转换矩阵，\n",
    "                         [0,1,0,0],   # 象征着没有任何位移，没有任何旋转，我们输入\n",
    "                         [0,0,1,0],   # 这个矩阵为初始变换\n",
    "                         [0,0,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b65b6d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#运行icp\n",
    "reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "        source, target, threshold, trans_init,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91146680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegistrationResult with fitness=1.000000e+00, inlier_rmse=2.578777e-01, and correspondence_set size of 300304\n",
      "Access transformation to get result.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PointCloud with 300304 points."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(reg_p2p)\n",
    "source.transform(reg_p2p.transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3a94177",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([source,target])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3876322",
   "metadata": {},
   "source": [
    "## METHOD 3 ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "461a7cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================读取点云数据===================\n",
    "source = o3d.io.read_point_cloud(\"./pcd/s_300.ply\")\n",
    "target = o3d.io.read_point_cloud(\"./pcd/s_350.ply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10645ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9df4291e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_point_cloud(pcd, voxel_size):\n",
    "    print(\":: Downsample with a voxel size %.3f.\" % voxel_size)\n",
    "    pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "\n",
    "    radius_normal = voxel_size * 2\n",
    "    print(\":: Estimate normal with search radius %.3f.\" % radius_normal)\n",
    "    pcd_down.estimate_normals(\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "\n",
    "    radius_feature = voxel_size * 5\n",
    "    print(\":: Compute FPFH feature with search radius %.3f.\" % radius_feature)\n",
    "    pcd_fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "        pcd_down,\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))\n",
    "    return pcd_down, pcd_fpfh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bbdb944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Load two point clouds and disturb initial pose.\n",
      ":: Downsample with a voxel size 0.050.\n",
      ":: Estimate normal with search radius 0.100.\n",
      ":: Compute FPFH feature with search radius 0.250.\n",
      ":: Downsample with a voxel size 0.050.\n",
      ":: Estimate normal with search radius 0.100.\n",
      ":: Compute FPFH feature with search radius 0.250.\n"
     ]
    }
   ],
   "source": [
    "def prepare_dataset(source,target, voxel_size):\n",
    "    print(\":: Load two point clouds and disturb initial pose.\")\n",
    "#     source = o3d.io.read_point_cloud(\"../../TestData/ICP/cloud_bin_0.pcd\")\n",
    "#     target = o3d.io.read_point_cloud(\"../../TestData/ICP/cloud_bin_1.pcd\")\n",
    "    trans_init = np.asarray([[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0],\n",
    "                             [0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0]])\n",
    "    source.transform(trans_init)\n",
    "    draw_registration_result(source, target, np.identity(4))\n",
    "\n",
    "    source_down, source_fpfh = preprocess_point_cloud(source, voxel_size)\n",
    "    target_down, target_fpfh = preprocess_point_cloud(target, voxel_size)\n",
    "    return source, target, source_down, target_down, source_fpfh, target_fpfh\n",
    "\n",
    "voxel_size = 0.05 # means 5cm for this dataset\n",
    "source, target, source_down, target_down, source_fpfh, target_fpfh = prepare_dataset(source,target,voxel_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b39fe19",
   "metadata": {},
   "source": [
    "我们使用RANSAC进行全局配准.在RANSAC迭代中，我们每次从源点云中选取　ransac_n 个随机点.通过在33维FPFH特征空间中查询最邻近,可以在目标点云中找到他们的对应点.剪枝步骤需要使用快速修剪算法来提早拒绝错误匹配.\n",
    "Open3d提供以下剪枝算法:\n",
    "\n",
    "CorrespondenceCheckerBasedOnDistance检查对应的点云是否接近(也就是距离是否小于指定阈值)\n",
    "\n",
    "CorrespondenceCheckerBasedOnEdgeLength检查从源点云和目标点云对应中分别画上两条任意边(两个顶点连成的线)是否近似.\n",
    "\n",
    "CorrespondenceCheckerBasedOnNormal考虑的所有的对应的顶点法线的密切关系.他计算了两个法线向量的点积.使用弧度作为阈值.\n",
    "\n",
    "只有通过剪枝步骤的匹配才用于转换,该转换将在整个点云上进行验证.核心函数是 ：\n",
    "\n",
    "registration_ransac_based_on_feature_matching. \n",
    "\n",
    "RANSACConvergenceCriteria是里面一个十分重要的超参数.他定义了RANSAC迭代的最大次数和验证的最大次数.这两个值越大,那么结果越准确,但同时也要花费更多的时间.\n",
    "我们是基于[Choi2015]提供的的经验来设置RANSAC的超参数."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2833a59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_global_registration(source_down, target_down, source_fpfh, target_fpfh, voxel_size):\n",
    "    distance_threshold = voxel_size * 1.5\n",
    "    print(\":: 对下采样的点云进行RANSAC配准.\")\n",
    "    print(\"   下采样体素的大小为： %.3f,\" % voxel_size)\n",
    "    print(\"   使用宽松的距离阈值： %.3f.\" % distance_threshold)\n",
    "    result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "        source_down, target_down, source_fpfh, target_fpfh, True, distance_threshold,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint(False), 3,\n",
    "        [o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(0.9),\n",
    "         o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)\n",
    "         ], o3d.pipelines.registration.RANSACConvergenceCriteria(100000, 0.999))\n",
    "    return result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eed51b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: 对下采样的点云进行RANSAC配准.\n",
      "   下采样体素的大小为： 0.050,\n",
      "   使用宽松的距离阈值： 0.075.\n",
      "RegistrationResult with fitness=2.654012e-01, inlier_rmse=4.487812e-02, and correspondence_set size of 1538\n",
      "Access transformation to get result.\n"
     ]
    }
   ],
   "source": [
    "result_ransac = execute_global_registration(source_down, target_down, source_fpfh, target_fpfh, voxel_size)\n",
    "print(result_ransac)\n",
    "draw_registration_result(source_down, target_down, result_ransac.transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92e08a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: 对原始点云进行点对面ICP配准精细对齐， 这次使用严格的距离阈值： 0.020.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[Open3D Error] (class open3d::pipelines::registration::RegistrationResult __cdecl open3d::pipelines::registration::RegistrationICP(const class open3d::geometry::PointCloud &,const class open3d::geometry::PointCloud &,double,const class Eigen::Matrix<double,4,4,0,4,4> &,const class open3d::pipelines::registration::TransformationEstimation &,const class open3d::pipelines::registration::ICPConvergenceCriteria &)) D:\\a\\Open3D\\Open3D\\cpp\\open3d\\pipelines\\registration\\Registration.cpp:147: TransformationEstimationPointToPlane and TransformationEstimationColoredICP require pre-computed normal vectors for target PointCloud.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-6c3e43363f3f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mresult_icp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrefine_registration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource_fpfh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_fpfh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvoxel_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_icp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mdraw_registration_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_icp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-6c3e43363f3f>\u001b[0m in \u001b[0;36mrefine_registration\u001b[1;34m(source, target, source_fpfh, target_fpfh, voxel_size)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mdistance_threshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvoxel_size\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m0.4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\":: 对原始点云进行点对面ICP配准精细对齐， 这次使用严格的距离阈值： %.3f.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdistance_threshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo3d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipelines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregistration\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregistration_icp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdistance_threshold\u001b[0m\u001b[1;33m,\u001b[0m                                            \u001b[0mresult_ransac\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mo3d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipelines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregistration\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTransformationEstimationPointToPlane\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [Open3D Error] (class open3d::pipelines::registration::RegistrationResult __cdecl open3d::pipelines::registration::RegistrationICP(const class open3d::geometry::PointCloud &,const class open3d::geometry::PointCloud &,double,const class Eigen::Matrix<double,4,4,0,4,4> &,const class open3d::pipelines::registration::TransformationEstimation &,const class open3d::pipelines::registration::ICPConvergenceCriteria &)) D:\\a\\Open3D\\Open3D\\cpp\\open3d\\pipelines\\registration\\Registration.cpp:147: TransformationEstimationPointToPlane and TransformationEstimationColoredICP require pre-computed normal vectors for target PointCloud.\n"
     ]
    }
   ],
   "source": [
    "def refine_registration(source, target, source_fpfh, target_fpfh, voxel_size):\n",
    "    distance_threshold = voxel_size * 0.4\n",
    "    print(\":: 对原始点云进行点对面ICP配准精细对齐， 这次使用严格的距离阈值： %.3f.\" % distance_threshold)\n",
    "    result = o3d.pipelines.registration.registration_icp(source, target, distance_threshold,                                            result_ransac.transformation,o3d.pipelines.registration.TransformationEstimationPointToPlane())\n",
    "    return result\n",
    "\n",
    "\n",
    "result_icp = refine_registration(source, target, source_fpfh, target_fpfh, voxel_size)\n",
    "print(result_icp)\n",
    "draw_registration_result(source, target, result_icp.transformation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41789fca",
   "metadata": {},
   "source": [
    "## METHOD 4 ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f77c2941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "#     source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "#     target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9e54825",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_point_cloud(pcd, voxel_size):\n",
    "    print(\":: 使用大小为为{}的体素下采样点云.\".format(voxel_size))\n",
    "    pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "\n",
    "    radius_normal = voxel_size * 2\n",
    "    print(\":: 使用搜索半径为{}估计法线\".format(radius_normal))\n",
    "    pcd_down.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "\n",
    "    radius_feature = voxel_size * 5\n",
    "    print(\":: 使用搜索半径为{}计算FPFH特征\".format(radius_feature))\n",
    "    pcd_fpfh = o3d.pipelines.registration.compute_fpfh_feature(pcd_down, o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))\n",
    "    return pcd_down, pcd_fpfh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a957b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: 加载点云并转换点云的位姿.\n",
      ":: 使用大小为为0.05的体素下采样点云.\n",
      ":: 使用搜索半径为0.1估计法线\n",
      ":: 使用搜索半径为0.25计算FPFH特征\n",
      ":: 使用大小为为0.05的体素下采样点云.\n",
      ":: 使用搜索半径为0.1估计法线\n",
      ":: 使用搜索半径为0.25计算FPFH特征\n"
     ]
    }
   ],
   "source": [
    "def prepare_dataset(voxel_size):\n",
    "    print(\":: 加载点云并转换点云的位姿.\")\n",
    "    source = o3d.io.read_point_cloud(\"./pcd/s_300.ply\")\n",
    "    target = o3d.io.read_point_cloud(\"./pcd/s_325.ply\")\n",
    "    trans_init = np.asarray([[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0],\n",
    "                             [0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0]])\n",
    "    source.transform(trans_init)\n",
    "    draw_registration_result(source, target, np.identity(4))\n",
    "\n",
    "    source_down, source_fpfh = preprocess_point_cloud(source, voxel_size)\n",
    "    target_down, target_fpfh = preprocess_point_cloud(target, voxel_size)\n",
    "    return source, target, source_down, target_down, source_fpfh, target_fpfh\n",
    "\n",
    "# 相当于使用5cm的体素对点云进行均值操作\n",
    "voxel_size = 0.05  # means 5cm for this dataset\n",
    "source, target, source_down, target_down, source_fpfh, target_fpfh = prepare_dataset(voxel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bbdc2cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: 对下采样的点云进行RANSAC配准.\n",
      "   下采样体素的大小为： 0.050,\n",
      "   使用宽松的距离阈值： 0.075.\n",
      "RegistrationResult with fitness=5.680759e-01, inlier_rmse=3.266798e-02, and correspondence_set size of 3292\n",
      "Access transformation to get result.\n"
     ]
    }
   ],
   "source": [
    "def execute_global_registration(source_down, target_down, source_fpfh, target_fpfh, voxel_size):\n",
    "    distance_threshold = voxel_size * 1.5\n",
    "    print(\":: 对下采样的点云进行RANSAC配准.\")\n",
    "    print(\"   下采样体素的大小为： %.3f,\" % voxel_size)\n",
    "    print(\"   使用宽松的距离阈值： %.3f.\" % distance_threshold)\n",
    "    result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "        source_down, target_down, source_fpfh, target_fpfh, True, distance_threshold,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint(False), 3,\n",
    "        [o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(0.9),\n",
    "         o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)\n",
    "         ], o3d.pipelines.registration.RANSACConvergenceCriteria(100000, 0.999))\n",
    "    return result\n",
    "\n",
    "\n",
    "result_ransac = execute_global_registration(source_down, target_down, source_fpfh, target_fpfh, voxel_size)\n",
    "print(result_ransac)\n",
    "draw_registration_result(source_down, target_down, result_ransac.transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f31afbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: 对原始点云进行点对面ICP配准精细对齐， 这次使用严格的距离阈值： 0.020.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[Open3D Error] (class open3d::pipelines::registration::RegistrationResult __cdecl open3d::pipelines::registration::RegistrationICP(const class open3d::geometry::PointCloud &,const class open3d::geometry::PointCloud &,double,const class Eigen::Matrix<double,4,4,0,4,4> &,const class open3d::pipelines::registration::TransformationEstimation &,const class open3d::pipelines::registration::ICPConvergenceCriteria &)) D:\\a\\Open3D\\Open3D\\cpp\\open3d\\pipelines\\registration\\Registration.cpp:147: TransformationEstimationPointToPlane and TransformationEstimationColoredICP require pre-computed normal vectors for target PointCloud.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-386bedd989fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mresult_icp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrefine_registration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource_fpfh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_fpfh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvoxel_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_icp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mdraw_registration_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_icp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-386bedd989fa>\u001b[0m in \u001b[0;36mrefine_registration\u001b[1;34m(source, target, source_fpfh, target_fpfh, voxel_size)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mdistance_threshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvoxel_size\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m0.4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\":: 对原始点云进行点对面ICP配准精细对齐， 这次使用严格的距离阈值： %.3f.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdistance_threshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     result = o3d.pipelines.registration.registration_icp(source, target, distance_threshold,\n\u001b[0m\u001b[0;32m      5\u001b[0m                                                          \u001b[0mresult_ransac\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                                                     o3d.pipelines.registration.TransformationEstimationPointToPlane())\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [Open3D Error] (class open3d::pipelines::registration::RegistrationResult __cdecl open3d::pipelines::registration::RegistrationICP(const class open3d::geometry::PointCloud &,const class open3d::geometry::PointCloud &,double,const class Eigen::Matrix<double,4,4,0,4,4> &,const class open3d::pipelines::registration::TransformationEstimation &,const class open3d::pipelines::registration::ICPConvergenceCriteria &)) D:\\a\\Open3D\\Open3D\\cpp\\open3d\\pipelines\\registration\\Registration.cpp:147: TransformationEstimationPointToPlane and TransformationEstimationColoredICP require pre-computed normal vectors for target PointCloud.\n"
     ]
    }
   ],
   "source": [
    "def refine_registration(source, target, source_fpfh, target_fpfh, voxel_size):\n",
    "    distance_threshold = voxel_size * 0.4\n",
    "    print(\":: 对原始点云进行点对面ICP配准精细对齐， 这次使用严格的距离阈值： %.3f.\" % distance_threshold)\n",
    "    result = o3d.pipelines.registration.registration_icp(source, target, distance_threshold,\n",
    "                                                         result_ransac.transformation,\n",
    "                                                    o3d.pipelines.registration.TransformationEstimationPointToPlane())\n",
    "    return result\n",
    "\n",
    "\n",
    "result_icp = refine_registration(source, target, source_fpfh, target_fpfh, voxel_size)\n",
    "print(result_icp)\n",
    "draw_registration_result(source, target, result_icp.transformation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
