{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "416c2cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fb59383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_point_cloud(pic1:str,pic2:str):\n",
    "    print(\"Read Redwood dataset\")\n",
    "    color_raw = o3d.io.read_image(pic1)\n",
    "    depth_raw = o3d.io.read_image(pic2)\n",
    "    rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(color_raw, depth_raw,convert_rgb_to_intensity=False)\n",
    "    pcd = o3d.geometry.PointCloud.create_from_rgbd_image(\n",
    "        rgbd_image,\n",
    "        o3d.camera.PinholeCameraIntrinsic(o3d.camera.PinholeCameraIntrinsicParameters.PrimeSenseDefault),\n",
    "#         o3d.camera.PinholeCameraIntrinsic(o3d.camera.PinholeCameraIntrinsicParameters.Kinect2DepthCameraDefault),\n",
    "#         project_valid_depth_only=False\n",
    "    )\n",
    "    # Flip it, otherwise the pointcloud will be upside down\n",
    "    pcd.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\n",
    "    return pcd\n",
    "#     o3d.io.write_point_cloud(\"sample.ply\", pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "333abc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read Redwood dataset\n",
      "Read Redwood dataset\n",
      "Read Redwood dataset\n"
     ]
    }
   ],
   "source": [
    "sample_0 = generate_point_cloud('./data/redwood/image/00000.jpg','./data/redwood/depth/00000.png')\n",
    "sample_1 = generate_point_cloud('./data/redwood/image/00100.jpg','./data/redwood/depth/00100.png')\n",
    "sample_2 = generate_point_cloud('./data/redwood/image/00200.jpg','./data/redwood/depth/00200.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcb07b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read Redwood dataset\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'camera' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-8686239906b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ms_300\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_point_cloud\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data/redwood/image/00300.jpg'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'./data/redwood/depth/00300.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0ms_325\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_point_cloud\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data/redwood/image/00325.jpg'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'./data/redwood/depth/00325.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0ms_350\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_point_cloud\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data/redwood/image/00350.jpg'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'./data/redwood/depth/00350.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-c35333ab5fdf>\u001b[0m in \u001b[0;36mgenerate_point_cloud\u001b[1;34m(pic1, pic2)\u001b[0m\n\u001b[0;32m      6\u001b[0m     pcd = o3d.geometry.PointCloud.create_from_rgbd_image(\n\u001b[0;32m      7\u001b[0m         \u001b[0mrgbd_image\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mcamera\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPinholeCameraIntrinsic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo3d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcamera\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPinholeCameraIntrinsicParameters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPrimeSenseDefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;31m#         o3d.camera.PinholeCameraIntrinsic(o3d.camera.PinholeCameraIntrinsicParameters.Kinect2DepthCameraDefault),\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#         project_valid_depth_only=False\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'camera' is not defined"
     ]
    }
   ],
   "source": [
    "s_300 = generate_point_cloud('./data/redwood/image/00300.jpg','./data/redwood/depth/00300.png')\n",
    "s_325 = generate_point_cloud('./data/redwood/image/00325.jpg','./data/redwood/depth/00325.png')\n",
    "s_350 = generate_point_cloud('./data/redwood/image/00350.jpg','./data/redwood/depth/00350.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0eba9df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([s_300])\n",
    "# o3d.visualization.draw_geometries([sample_1])\n",
    "# o3d.visualization.draw_geometries([sample_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a8b77f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o3d.io.write_point_cloud(\"s_325.ply\", s_325)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7396e51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c5e543e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf1d925",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2273da3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#多视角点云配准\n",
    "#多视角配准是在全局空间中对齐多个几何形状的过程。比较有代表性的是，输入是一组几何形状 { P i }\n",
    "#（可以是点云或者RGBD图像）。输出是一组刚性变换{ T i }\n",
    "#变换后的点云 { T i P i }可以在全局空间中对齐。\n",
    "pcds = [sample_0,sample_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fd41520",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries(pcds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b449bec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "#姿态图\n",
    "#姿态图有两个关键的基础：节点和边。节点是与姿态矩阵Ti关联的一组几何体Pi,\n",
    "#通过该矩阵能够将Pi转换到全局空间。集和{ T i }是一组待优化的未知的变量\n",
    "#PoseGraph.nodes是PoseGraphNode的列表。我们设P0的空间是全局空间\n",
    "#因此T0是单位矩阵。其他的姿态矩阵通过累加相邻节点之间的变换来初始化。相邻节点通常都有着大规模的重叠并且能够通过Point-to-plane ICP来配准。\n",
    " \n",
    "# 下面的脚本创造了具有三个节点和三个边的姿态图。\n",
    "# 这些边里，两个是odometry edges（uncertain = False），一个是loop closure edge（uncertain = True）。\n",
    "def pairwise_registration(source, target):\n",
    "    print(\"Apply point-to-plane ICP\")\n",
    "    \n",
    "    target.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size * 2.0, max_nn=30))\n",
    "    \n",
    "    icp_coarse = o3d.pipelines.registration.registration_icp(\n",
    "        source, target, max_correspondence_distance_coarse, np.identity(4),\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPlane())\n",
    "    icp_fine = o3d.pipelines.registration.registration_icp(\n",
    "        source, target, max_correspondence_distance_fine,\n",
    "        icp_coarse.transformation,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPlane())\n",
    "    transformation_icp = icp_fine.transformation\n",
    "    information_icp = o3d.pipelines.registration.get_information_matrix_from_point_clouds(\n",
    "        source, target, max_correspondence_distance_fine,\n",
    "        icp_fine.transformation)\n",
    "    return transformation_icp, information_icp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bf0e152",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def full_registration(pcds, max_correspondence_distance_coarse,max_correspondence_distance_fine):\n",
    "    pose_graph = o3d.pipelines.registration.PoseGraph()\n",
    "    odometry = np.identity(4)\n",
    "    pose_graph.nodes.append(o3d.pipelines.registration.PoseGraphNode(odometry))\n",
    "    n_pcds = len(pcds)\n",
    "    for source_id in range(n_pcds):\n",
    "        for target_id in range(source_id + 1, n_pcds):\n",
    "            transformation_icp, information_icp = pairwise_registration(\n",
    "                pcds[source_id], pcds[target_id])\n",
    "            print(\"Build o3d.pipelines.registration.PoseGraph\")\n",
    "            if target_id == source_id + 1:  # odometry case\n",
    "                odometry = np.dot(transformation_icp, odometry)\n",
    "                pose_graph.nodes.append(\n",
    "                    o3d.pipelines.registration.PoseGraphNode(np.linalg.inv(odometry)))\n",
    "                pose_graph.edges.append(\n",
    "                    o3d.pipelines.registration.PoseGraphEdge(source_id,\n",
    "                                                   target_id,\n",
    "                                                   transformation_icp,\n",
    "                                                   information_icp,\n",
    "                                                   uncertain=False))\n",
    "            else:  # loop closure case\n",
    "                pose_graph.edges.append(\n",
    "                    o3d.pipelines.registration.PoseGraphEdge(source_id,\n",
    "                                                   target_id,\n",
    "                                                   transformation_icp,\n",
    "                                                   information_icp,\n",
    "                                                   uncertain=True))\n",
    "    return pose_graph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c953930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_cloud_fusion(pcds):\n",
    "    global voxel_size\n",
    "    global max_correspondence_distance_coarse\n",
    "    global max_correspondence_distance_fine\n",
    "    \n",
    "    voxel_size = 0.02\n",
    "    # pcds_down = load_point_clouds(voxel_size)\n",
    "    pcds_down = pcds\n",
    "#     o3d.visualization.draw_geometries(pcds_down)\n",
    "    print(\"Full registration ...\")\n",
    "\n",
    "    max_correspondence_distance_coarse = voxel_size * 15\n",
    "    max_correspondence_distance_fine = voxel_size * 1.5\n",
    "    with o3d.utility.VerbosityContextManager(o3d.utility.VerbosityLevel.Debug) as cm:\n",
    "        pose_graph = full_registration(pcds_down,\n",
    "                                       max_correspondence_distance_coarse,\n",
    "                                       max_correspondence_distance_fine)\n",
    "    #Open3d使用函数global_optimization进行姿态图估计，可以选择两种类型的优化算法，分别是GlobalOptimizationGaussNewton和GlobalOptimizationLevenbergMarquardt。\n",
    "    # 比较推荐后一种的原因是因为它具有比较好的收敛性。GlobalOptimizationConvergenceCriteria类可以用来设置最大迭代次数和别的优化参数。\n",
    "    #GlobalOptimizationOption定于了两个参数。max_correspondence_distance定义了对应阈值。edge_prune_threshold是修剪异常边缘的阈值。reference_node是被视为全局空间的节点ID。\n",
    "    print(\"Optimizing PoseGraph ...\")\n",
    "    option = o3d.pipelines.registration.GlobalOptimizationOption(\n",
    "        max_correspondence_distance=max_correspondence_distance_fine,\n",
    "        edge_prune_threshold=0.25,\n",
    "        reference_node=0)\n",
    "    with o3d.utility.VerbosityContextManager(o3d.utility.VerbosityLevel.Debug) as cm:\n",
    "        o3d.pipelines.registration.global_optimization(\n",
    "            pose_graph, o3d.pipelines.registration.GlobalOptimizationLevenbergMarquardt(),\n",
    "            o3d.pipelines.registration.GlobalOptimizationConvergenceCriteria(), option)\n",
    "    #全局优化在姿态图上执行两次。\n",
    "    # 第一遍将考虑所有边缘的情况优化原始姿态图的姿态，并尽量区分不确定边缘之间的错误对齐。这些错误对齐将会产生小的 line process weights，他们将会在第一遍被剔除。\n",
    "    # 第二遍将会在没有这些边的情况下运行，产生更紧密地全局对齐效果。在这个例子中，所有的边都将被考虑为真实的匹配，所以第二遍将会立即终止。\n",
    "\n",
    "    #可视化操作\n",
    "    #使用```draw_geometries``函数可视化变换点云。\n",
    "    print(\"Transform points and display\")\n",
    "    for point_id in range(len(pcds_down)):\n",
    "        print(pose_graph.nodes[point_id].pose)\n",
    "        pcds_down[point_id].transform(pose_graph.nodes[point_id].pose)\n",
    "#     o3d.visualization.draw_geometries(pcds_down)\n",
    "\n",
    "    #得到合并的点云\n",
    "    #PointCloud是可以很方便的使用+来合并两组点云成为一个整体。\n",
    "    # 合并之后，将会使用voxel_down_sample进行重新采样。建议在合并之后对点云进行后处理，因为这样可以减少重复的点后者较为密集的点。\n",
    "    \n",
    "#     pcds = load_point_clouds(voxel_size)\n",
    "    pcd_combined = o3d.geometry.PointCloud()\n",
    "    for point_id in range(len(pcds)):\n",
    "        pcds[point_id].transform(pose_graph.nodes[point_id].pose)\n",
    "        pcd_combined += pcds[point_id]\n",
    "    pcd_combined_down = pcd_combined.voxel_down_sample(voxel_size=0.02)\n",
    "#     o3d.io.write_point_cloud(\"new_registration.ply\", pcd_combined_down)\n",
    "    o3d.visualization.draw_geometries([pcd_combined_down])\n",
    "    return pcd_combined_down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b4dca6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full registration ...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'open3d' has no attribute 'pipelines'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-e5b68cd6ebcd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcombined_point\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mpoint_cloud_fusion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpcds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-bad2a8512ed2>\u001b[0m in \u001b[0;36mpoint_cloud_fusion\u001b[1;34m(pcds)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mmax_correspondence_distance_fine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvoxel_size\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m1.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mo3d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutility\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVerbosityContextManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo3d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutility\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVerbosityLevel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDebug\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         pose_graph = full_registration(pcds_down,\n\u001b[0m\u001b[0;32m     16\u001b[0m                                        \u001b[0mmax_correspondence_distance_coarse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                                        max_correspondence_distance_fine)\n",
      "\u001b[1;32m<ipython-input-9-9b159ce8c6f0>\u001b[0m in \u001b[0;36mfull_registration\u001b[1;34m(pcds, max_correspondence_distance_coarse, max_correspondence_distance_fine)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfull_registration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpcds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_correspondence_distance_coarse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_correspondence_distance_fine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mpose_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo3d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipelines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregistration\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPoseGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0modometry\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mpose_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo3d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipelines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregistration\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPoseGraphNode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0modometry\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mn_pcds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpcds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'open3d' has no attribute 'pipelines'"
     ]
    }
   ],
   "source": [
    "combined_point =  point_cloud_fusion(pcds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50d0e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([cloud2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f4839e",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([combined_point])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd32635",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.io.write_point_cloud(\"sample_2.ply\", sample_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
